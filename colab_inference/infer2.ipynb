{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"infer2.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"}},"cells":[{"cell_type":"code","metadata":{"colab_type":"code","id":"oJ-O1t4bATth","outputId":"bd85fe80-4caf-4212-c8f9-88f329e71799","scrolled":true,"executionInfo":{"status":"ok","timestamp":1576064509480,"user_tz":-330,"elapsed":6062,"user":{"displayName":"Face Detection","photoUrl":"","userId":"01433683970229031124"}},"colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["!pip install Torch==0.3.1\n"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: Torch==0.3.1 in /usr/local/lib/python3.6/dist-packages (0.3.1)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from Torch==0.3.1) (3.13)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from Torch==0.3.1) (1.17.4)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"NTekWu-OAp2C","outputId":"f6b43008-016a-4410-d8af-b96567b9d2bc","executionInfo":{"status":"ok","timestamp":1576064513862,"user_tz":-330,"elapsed":10432,"user":{"displayName":"Face Detection","photoUrl":"","userId":"01433683970229031124"}},"colab":{"base_uri":"https://localhost:8080/","height":136}},"source":["!pip install Torchvision==0.2.1"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: Torchvision==0.2.1 in /usr/local/lib/python3.6/dist-packages (0.2.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from Torchvision==0.2.1) (1.12.0)\n","Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from Torchvision==0.2.1) (4.3.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from Torchvision==0.2.1) (1.17.4)\n","Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from Torchvision==0.2.1) (0.3.1)\n","Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=4.1.1->Torchvision==0.2.1) (0.46)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from torch->Torchvision==0.2.1) (3.13)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"PKyc13d4Ascv","outputId":"357a473f-eab7-44fe-cfc2-cca8704a3089","executionInfo":{"status":"ok","timestamp":1576064517783,"user_tz":-330,"elapsed":14343,"user":{"displayName":"Face Detection","photoUrl":"","userId":"01433683970229031124"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["!git clone https://github.com/TencentYoutuResearch/FaceDetection-DSFD.git"],"execution_count":6,"outputs":[{"output_type":"stream","text":["fatal: destination path 'FaceDetection-DSFD' already exists and is not an empty directory.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"EQXrLdu5A3fG","outputId":"e849c788-4b01-4e16-d852-debc8ddb183d","executionInfo":{"status":"ok","timestamp":1576064517784,"user_tz":-330,"elapsed":14333,"user":{"displayName":"Face Detection","photoUrl":"","userId":"01433683970229031124"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"cm2Zo2f7A5E6","outputId":"d5c13c6c-9579-4847-c5a6-ffe1623d2728","executionInfo":{"status":"ok","timestamp":1576064517786,"user_tz":-330,"elapsed":14324,"user":{"displayName":"Face Detection","photoUrl":"","userId":"01433683970229031124"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["%cd /content/FaceDetection-DSFD"],"execution_count":8,"outputs":[{"output_type":"stream","text":["/content/FaceDetection-DSFD\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"IjT9EwG-HKpM","colab_type":"code","colab":{}},"source":["%cp /content/drive/My\\ Drive/WIDERFace_DSFD_RES152.pth /content/FaceDetection-DSFD/weights"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"PV5ozxH8C-Yo","outputId":"fe0855ac-cb42-46be-f3f1-527e1a1ea9ca","executionInfo":{"status":"ok","timestamp":1576064542478,"user_tz":-330,"elapsed":38997,"user":{"displayName":"Face Detection","photoUrl":"","userId":"01433683970229031124"}},"colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["!python demo.py"],"execution_count":10,"outputs":[{"output_type":"stream","text":["loading pretrained resnet model\n","Finished loading model!\n","650\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"qGaZJNuaW80k","colab":{}},"source":["from __future__ import print_function \n","import sys\n","import os\n","import argparse\n","import torch\n","import torch.nn as nn\n","import torch.backends.cudnn as cudnn\n","import torchvision.transforms as transforms\n","from torch.autograd import Variable\n","from data import WIDERFace_ROOT , WIDERFace_CLASSES as labelmap\n","from PIL import Image\n","from data import WIDERFaceDetection, WIDERFaceAnnotationTransform, WIDERFace_CLASSES, WIDERFace_ROOT, BaseTransform , TestBaseTransform\n","from data import *\n","import torch.utils.data as data\n","from face_ssd import build_ssd\n","#from resnet50_ssd import build_sfd\n","import pdb\n","import numpy as np\n","import cv2\n","import math\n","import matplotlib.pyplot as plt\n","import time\n","plt.switch_backend('agg')\n","\n","\n","widerface_root=\"WIDERFace_ROOT\"\n","trained_model = \"/content/drive/My Drive/WIDERFace_DSFD_RES152.pth\"\n","save_folder = \"eval_tools/\"\n","visual_threshold = 0.1\n","cuda = True\n","img_root=\"./data/worlds-largest-selfie.jpg\"\n","\n","\n","\n","if cuda and torch.cuda.is_available():\n","    torch.set_default_tensor_type('torch.cuda.FloatTensor')\n","else:\n","    torch.set_default_tensor_type('torch.FloatTensor')\n","if not os.path.exists(save_folder):\n","    os.mkdir(save_folder)\n","\n","\n","def bbox_vote(det):\n","    order = det[:, 4].ravel().argsort()[::-1]\n","    det = det[order, :]\n","    while det.shape[0] > 0:\n","        # IOU\n","        area = (det[:, 2] - det[:, 0] + 1) * (det[:, 3] - det[:, 1] + 1)\n","        xx1 = np.maximum(det[0, 0], det[:, 0])\n","        yy1 = np.maximum(det[0, 1], det[:, 1])\n","        xx2 = np.minimum(det[0, 2], det[:, 2])\n","        yy2 = np.minimum(det[0, 3], det[:, 3])\n","        w = np.maximum(0.0, xx2 - xx1 + 1)\n","        h = np.maximum(0.0, yy2 - yy1 + 1)\n","        inter = w * h\n","        o = inter / (area[0] + area[:] - inter)\n","        # get needed merge det and delete these det\n","        merge_index = np.where(o >= 0.3)[0]\n","        det_accu = det[merge_index, :]\n","        det = np.delete(det, merge_index, 0)\n","        if merge_index.shape[0] <= 1:\n","            continue\n","        det_accu[:, 0:4] = det_accu[:, 0:4] * np.tile(det_accu[:, -1:], (1, 4))\n","        max_score = np.max(det_accu[:, 4])\n","        det_accu_sum = np.zeros((1, 5))\n","        det_accu_sum[:, 0:4] = np.sum(det_accu[:, 0:4], axis=0) / np.sum(det_accu[:, -1:])\n","        det_accu_sum[:, 4] = max_score\n","        try:\n","            dets = np.row_stack((dets, det_accu_sum))\n","        except:\n","            dets = det_accu_sum\n","    dets = dets[0:750, :]\n","    return dets\n","\n","def write_to_txt(f, det , event , im_name):\n","    f.write('{:s}\\n'.format(event + '/' + im_name))\n","    f.write('{:d}\\n'.format(det.shape[0]))\n","    for i in range(det.shape[0]):\n","        xmin = det[i][0]\n","        ymin = det[i][1]\n","        xmax = det[i][2]\n","        ymax = det[i][3]\n","        score = det[i][4] \n","        f.write('{:.1f} {:.1f} {:.1f} {:.1f} {:.3f}\\n'.\n","                format(xmin, ymin, (xmax - xmin + 1), (ymax - ymin + 1), score))\n","\n","def infer(net , img , transform , thresh , cuda , shrink):\n","    if shrink != 1:\n","        img = cv2.resize(img, None, None, fx=shrink, fy=shrink, interpolation=cv2.INTER_LINEAR)\n","    x = torch.from_numpy(transform(img)[0]).permute(2, 0, 1)\n","    x = Variable(x.unsqueeze(0) , volatile=True)\n","    if cuda:\n","        x = x.cuda()\n","    #print (shrink , x.shape)\n","    y = net(x)      # forward pass\n","    detections = y.data\n","    # scale each detection back up to the image\n","    scale = torch.Tensor([ img.shape[1]/shrink, img.shape[0]/shrink,\n","                         img.shape[1]/shrink, img.shape[0]/shrink] )\n","    det = []\n","    for i in range(detections.size(1)):\n","        j = 0\n","        while detections[0, i, j, 0] >= thresh:\n","            score = detections[0, i, j, 0]\n","            #label_name = labelmap[i-1]\n","            pt = (detections[0, i, j, 1:]*scale).cpu().numpy()\n","            coords = (pt[0], pt[1], pt[2], pt[3]) \n","            det.append([pt[0], pt[1], pt[2], pt[3], score])\n","            j += 1\n","    if (len(det)) == 0:\n","        det = [ [0.1,0.1,0.2,0.2,0.01] ]\n","    det = np.array(det)\n","\n","    keep_index = np.where(det[:, 4] >= 0)[0]\n","    det = det[keep_index, :]\n","    return det\n","\n","def infer_flip(net , img , transform , thresh , cuda , shrink):\n","    img = cv2.flip(img, 1)\n","    det = infer(net , img , transform , thresh , cuda , shrink)\n","    det_t = np.zeros(det.shape)\n","    det_t[:, 0] = img.shape[1] - det[:, 2]\n","    det_t[:, 1] = det[:, 1]\n","    det_t[:, 2] = img.shape[1] - det[:, 0]\n","    det_t[:, 3] = det[:, 3]\n","    det_t[:, 4] = det[:, 4]\n","    return det_t\n","\n","\n","def infer_multi_scale_sfd(net , img , transform , thresh , cuda ,  max_im_shrink):\n","    # shrink detecting and shrink only detect big face\n","    st = 0.5 if max_im_shrink >= 0.75 else 0.5 * max_im_shrink\n","    det_s = infer(net , img , transform , thresh , cuda , st)\n","    index = np.where(np.maximum(det_s[:, 2] - det_s[:, 0] + 1, det_s[:, 3] - det_s[:, 1] + 1) > 30)[0]\n","    det_s = det_s[index, :]\n","    # enlarge one times\n","    bt = min(2, max_im_shrink) if max_im_shrink > 1 else (st + max_im_shrink) / 2\n","    det_b = infer(net , img , transform , thresh , cuda , bt)\n","    # enlarge small iamge x times for small face\n","    if max_im_shrink > 2:\n","        bt *= 2\n","        while bt < max_im_shrink:\n","            det_b = np.row_stack((det_b, infer(net , img , transform , thresh , cuda , bt)))\n","            bt *= 2\n","        det_b = np.row_stack((det_b, infer(net , img , transform , thresh , cuda , max_im_shrink) ))\n","    # enlarge only detect small face\n","    if bt > 1:\n","        index = np.where(np.minimum(det_b[:, 2] - det_b[:, 0] + 1, det_b[:, 3] - det_b[:, 1] + 1) < 100)[0]\n","        det_b = det_b[index, :]\n","    else:\n","        index = np.where(np.maximum(det_b[:, 2] - det_b[:, 0] + 1, det_b[:, 3] - det_b[:, 1] + 1) > 30)[0]\n","        det_b = det_b[index, :]\n","    return det_s, det_b\n","\n","\n","def vis_detections(im,  dets, image_name , thresh=0.5):\n","    \"\"\"Draw detected bounding boxes.\"\"\"\n","    class_name = 'face'\n","    inds = np.where(dets[:, -1] >= thresh)[0]\n","    if len(inds) == 0:\n","        return\n","    print (len(inds))\n","    im = im[:, :, (2, 1, 0)]\n","    fig, ax = plt.subplots(figsize=(12, 12))\n","    ax.imshow(im, aspect='equal')\n","    for i in inds:\n","        bbox = dets[i, :4]\n","        score = dets[i, -1]\n","        ax.add_patch(\n","            plt.Rectangle((bbox[0], bbox[1]),\n","                          bbox[2] - bbox[0],\n","                          bbox[3] - bbox[1], fill=False,\n","                          edgecolor='red', linewidth=2.5)\n","            )\n","        '''\n","        ax.text(bbox[0], bbox[1] - 5,\n","                '{:s} {:.3f}'.format(class_name, score),\n","                bbox=dict(facecolor='blue', alpha=0.5),\n","                fontsize=10, color='white')\n","        '''\n","    ax.set_title(('{} detections with '\n","                  'p({} | box) >= {:.1f}').format(class_name, class_name,\n","                                                  thresh),\n","                  fontsize=10)\n","    plt.axis('off')\n","    plt.tight_layout()\n","    plt.savefig(save_folder+image_name, dpi=fig.dpi)\n","\n","def output(im,  dets, image_name , thresh=0.5):\n","    \"\"\"Draw detected bounding boxes.\"\"\"\n","    str_=\"\"\n","    class_name = 'face'\n","    inds = np.where(dets[:, -1] >= thresh)[0]\n","    if len(inds) == 0:\n","        str_+=\"empty\"\n","        return\n","    print (len(inds))\n","    im = im[:, :, (2, 1, 0)]\n","    fig, ax = plt.subplots(figsize=(12, 12))\n","    ax.imshow(im, aspect='equal')\n","    for i in inds:\n","        bbox = dets[i, :4]\n","        score = dets[i, -1]\n","        \n","        xmin=bbox[0]\n","        ymin=bbox[1]\n","        xmax=bbox[2]\n","        ymax=bbox[3]\n","        boxes=[xmin,ymin,xmax,ymax]\n","        str_+=\" \"+str(xmin)+\" \"+str(ymin)+\" \"+str(xmax)+\" \"+str(ymax)\n","        ax.add_patch(\n","            plt.Rectangle((bbox[0], bbox[1]),\n","                          bbox[2] - bbox[0],\n","                          bbox[3] - bbox[1], fill=False,\n","                          edgecolor='red', linewidth=2.5)\n","            )\n","        '''\n","        ax.text(bbox[0], bbox[1] - 5,\n","                '{:s} {:.3f}'.format(class_name, score),\n","                bbox=dict(facecolor='blue', alpha=0.5),\n","                fontsize=10, color='white')\n","        '''\n","    txt.write(str_)\n","    txt.write(\"\\n\")\n","    ax.set_title(('{} detections with '\n","                  'p({} | box) >= {:.1f}').format(class_name, class_name,\n","                                                  thresh),\n","                  fontsize=10)\n","    plt.axis('off')\n","    plt.tight_layout()\n","    plt.savefig(save_folder+image_name, dpi=fig.dpi)\n","\n","\n","\n","\n","\n","\n","def test_oneimage():\n","    # load net\n","    cfg = widerface_640\n","    num_classes = len(WIDERFace_CLASSES) + 1 # +1 background\n","    net = build_ssd('test', cfg['min_dim'], num_classes) # initialize SSD\n","    net.load_state_dict(torch.load(trained_model))\n","    net.cuda()\n","    net.eval()\n","    print('Finished loading model!')\n","\n","    # evaluation\n","    cuda = cuda\n","    transform = TestBaseTransform((104, 117, 123))\n","    thresh=cfg['conf_thresh']\n","    #save_path = save_folder\n","    #num_images = len(testset)\n"," \n","    # load data\n","    path = img_root\n","    img_id = 'face'\n","    img = cv2.imread(path, cv2.IMREAD_COLOR)\n","\n","    max_im_shrink = ( (2000.0*2000.0) / (img.shape[0] * img.shape[1])) ** 0.5\n","    shrink = max_im_shrink if max_im_shrink < 1 else 1\n","\n","    det0 = infer(net , img , transform , thresh , cuda , shrink)\n","    det1 = infer_flip(net , img , transform , thresh , cuda , shrink)\n","    # shrink detecting and shrink only detect big face\n","    st = 0.5 if max_im_shrink >= 0.75 else 0.5 * max_im_shrink\n","    det_s = infer(net , img , transform , thresh , cuda , st)\n","    index = np.where(np.maximum(det_s[:, 2] - det_s[:, 0] + 1, det_s[:, 3] - det_s[:, 1] + 1) > 30)[0]\n","    det_s = det_s[index, :]\n","    # enlarge one times\n","    factor = 2\n","    bt = min(factor, max_im_shrink) if max_im_shrink > 1 else (st + max_im_shrink) / 2\n","    det_b = infer(net , img , transform , thresh , cuda , bt)\n","    # enlarge small iamge x times for small face\n","    if max_im_shrink > factor:\n","        bt *= factor\n","        while bt < max_im_shrink:\n","            det_b = np.row_stack((det_b, infer(net , img , transform , thresh , cuda , bt)))\n","            bt *= factor\n","        det_b = np.row_stack((det_b, infer(net , img , transform , thresh , cuda , max_im_shrink) ))\n","    # enlarge only detect small face\n","    if bt > 1:\n","        index = np.where(np.minimum(det_b[:, 2] - det_b[:, 0] + 1, det_b[:, 3] - det_b[:, 1] + 1) < 100)[0]\n","        det_b = det_b[index, :]\n","    else:\n","        index = np.where(np.maximum(det_b[:, 2] - det_b[:, 0] + 1, det_b[:, 3] - det_b[:, 1] + 1) > 30)[0]\n","        det_b = det_b[index, :]\n","    det = np.row_stack((det0, det1, det_s, det_b))\n","    det = bbox_vote(det)\n","    vis_detections(img , det , img_id, visual_threshold)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Y9HYBbXgXyR_","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":428},"outputId":"35b5ee12-fb0d-4b2b-9dfb-5f0e357f7cf0","executionInfo":{"status":"ok","timestamp":1576069257013,"user_tz":-330,"elapsed":150415,"user":{"displayName":"Face Detection","photoUrl":"","userId":"01433683970229031124"}}},"source":["cfg = widerface_640\n","num_classes = len(WIDERFace_CLASSES) + 1 # +1 background\n","net = build_ssd('test', cfg['min_dim'], num_classes) # initialize SSD\n","net.load_state_dict(torch.load(trained_model))\n","net.cuda()\n","net.eval()    \n","cuda = cuda\n","transform = TestBaseTransform((104, 117, 123))\n","thresh=cfg['conf_thresh']\n","\n","\n","textfile = 'bbox_op.txt'\n","filesdir='/content/drive/My Drive/FolderSeconds/'\n","with open(textfile,'w') as txt:\n","    for so in (sorted(os.listdir(filesdir))):\n","        path = os.path.join(filesdir,so)\n","        img_id = so\n","        print(img_id)\n","        # load data\n","        img = cv2.imread(path, cv2.IMREAD_COLOR)\n","\n","        max_im_shrink = ( (2000.0*2000.0) / (img.shape[0] * img.shape[1])) ** 0.5\n","        shrink = max_im_shrink if max_im_shrink < 1 else 1\n","\n","        det0 = infer(net , img , transform , thresh , cuda , shrink)\n","        det1 = infer_flip(net , img , transform , thresh , cuda , shrink)\n","        # shrink detecting and shrink only detect big face\n","        st = 0.5 if max_im_shrink >= 0.75 else 0.5 * max_im_shrink\n","        det_s = infer(net , img , transform , thresh , cuda , st)\n","        index = np.where(np.maximum(det_s[:, 2] - det_s[:, 0] + 1, det_s[:, 3] - det_s[:, 1] + 1) > 30)[0]\n","        det_s = det_s[index, :]\n","        # enlarge one times\n","        factor = 2\n","        bt = min(factor, max_im_shrink) if max_im_shrink > 1 else (st + max_im_shrink) / 2\n","        det_b = infer(net , img , transform , thresh , cuda , bt)\n","        # enlarge small iamge x times for small face\n","        if max_im_shrink > factor:\n","            bt *= factor\n","            while bt < max_im_shrink:\n","                det_b = np.row_stack((det_b, infer(net , img , transform , thresh , cuda , bt)))\n","                bt *= factor\n","            det_b = np.row_stack((det_b, infer(net , img , transform , thresh , cuda , max_im_shrink) ))\n","        # enlarge only detect small face\n","        if bt > 1:\n","            index = np.where(np.minimum(det_b[:, 2] - det_b[:, 0] + 1, det_b[:, 3] - det_b[:, 1] + 1) < 100)[0]\n","            det_b = det_b[index, :]\n","        else:\n","            index = np.where(np.maximum(det_b[:, 2] - det_b[:, 0] + 1, det_b[:, 3] - det_b[:, 1] + 1) > 30)[0]\n","            det_b = det_b[index, :]\n","        det = np.row_stack((det0, det1, det_s, det_b))\n","        det = bbox_vote(det)\n","        output(img , det , img_id, visual_threshold)\n","\n","\n","\n","\n","\n","\n"],"execution_count":41,"outputs":[{"output_type":"stream","text":["ERROR: You specified size [1440, 2560]. However, currently only SSD640 (size=640) is supported!\n","loading pretrained resnet model\n","frame1320.jpg\n","2\n","frame20460.jpg\n","1\n","frame2310.jpg\n","4\n","frame25080.jpg\n","5\n","frame25740.jpg\n","3\n","frame2640.jpg\n","1\n","frame330.jpg\n","1\n","frame660.jpg\n","4\n","frame6930.jpg\n","1\n","frame990.jpg\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:199: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n"],"name":"stderr"},{"output_type":"stream","text":["2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"WfufuuBwjLmh","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}